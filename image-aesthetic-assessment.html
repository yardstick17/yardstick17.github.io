<!doctype html>
<html lang="en" itemscope itemtype="http://schema.org/Person">
<head>
            <meta charset="utf-8">
        <!-- Site Meta Data -->

        <title>Image Aesthetic Assessment  </title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="">
        <meta name="author" content="Amit Kushwaha">

        <link rel="shortcut icon" href="http://localhost:8000/images/favicon.ico">

        <!-- schema.org -->
        <meta itemprop="name" content="Connecting Dots">
        <meta itemprop="image" content="">
        <meta itemprop="description" content="">

        <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,600,700' rel='stylesheet' type='text/css'>
        <!-- Style Meta Data -->
        <link rel="stylesheet" href="https://yardstick17.github.io/theme/css/style.css" type="text/css"/>
        <link rel="stylesheet" href="https://yardstick17.github.io/theme/css/pygments.css" type="text/css"/>
        <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600|Arvo:700" rel="stylesheet" type="text/css" />
        <link rel="stylesheet" href="css/font-awesome.min.css">

        <!-- Feed Meta Data -->
            <link href="https://yardstick17.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
                  title="Connecting Dots ATOM Feed"/>

        <!-- Twitter Feed -->
        <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="imYardstick17">
        <meta name="twitter:image" content="">

    <meta name="twitter:creator" content="imYardstick17">
    <meta name="twitter:url" content="https://yardstick17.github.io/image-aesthetic-assessment.html">
    <meta name="twitter:title" content="Connecting Dots ~ Image Aesthetic Assessment">
    <meta name="twitter:description" content="Image Aesthetic Assessment using Deep Learning. The defined network takes the complete image instead of fixed or re-sized input. This makes the network to learn for original image composition.">

    <!-- Facebook Meta Data -->
    <meta property="og:title" content="Connecting Dots ~ Image Aesthetic Assessment"/>
    <meta property="og:description" content="Image Aesthetic Assessment using Deep Learning. The defined network takes the complete image instead of fixed or re-sized input. This makes the network to learn for original image composition."/>
    <meta property="og:image" content=""/>
</head>

<body>
<!-- Sidebar -->
<aside>
    <!--<center><a href="https://yardstick17.github.io"><img id="avatar" src=""></a></center>-->
    <a href="https://yardstick17.github.io" style="color: white; text-decoration:none">
    <h1>Connecting Dots</h1>
    </a>
        <p>AI | NLP | DEEP LEARNING</p>
    <br>

        <a class="twitter-follow-button"
           href="https://twitter.com/imYardstick17"
           data-show-count="false"
           data-lang="en">
            Follow @twitterdev
        </a>
        <script type="text/javascript">
            window.twttr = (function (d, s, id) {
                var t, js, fjs = d.getElementsByTagName(s)[0];
                if (d.getElementById(id)) return;
                js = d.createElement(s);
                js.id = id;
                js.src = "https://platform.twitter.com/widgets.js";
                fjs.parentNode.insertBefore(js, fjs);
                return window.twttr || (t = {
                        _e: [], ready: function (f) {
                            t._e.push(f)
                        }
                    });
            }(document, "script", "twitter-wjs"));
        </script>

    <nav class="nav">
        <ul class="list-bare">

                <li><a class="nav__link" href="https://yardstick17.github.io/pages/about-me.html">About</a></li>
                <li><a class="nav__link" href="https://yardstick17.github.io">Blog</a></li>
                <li><a class="nav__link" href="https://yardstick17.github.io/archives.html">Archive</a></li>
                <li><a class="nav__link" href="https://yardstick17.github.io/categories.html">Categories</a></li>


        </ul>
    </nav>

    <p class="social">
                <a href="https://www.linkedin.com/in/yardstick17" target="_blank"><img
                        src="https://yardstick17.github.io/theme/images/icons/linkedin.png"></a>
                <a href="https://github.com/yardstick17" target="_blank"><img
                        src="https://yardstick17.github.io/theme/images/icons/github.png"></a>
                <a href="https://twitter.com/imYardstick17" target="_blank"><img
                        src="https://yardstick17.github.io/theme/images/icons/twitter.png"></a>
            <a href="https://yardstick17.github.io/feeds/all.atom.xml" rel="alternate">
                <img src="https://yardstick17.github.io/theme/images/icons/rss.png"></a>
    </p>

        <h2>Categories</h2>
        <ul class="navbar">
                <li class="active"><a
                        href="https://yardstick17.github.io/category/deep-learning.html">Deep Learning</a></li>
                <li><a
                        href="https://yardstick17.github.io/category/natural-language-processing.html">Natural Language Processing</a></li>
                <li><a
                        href="https://yardstick17.github.io/category/research-paper-explained.html">Research Paper Explained</a></li>
                <li><a
                        href="https://yardstick17.github.io/category/software-development.html">Software Development</a></li>
        </ul>

    <span>
        <a class="github-button" href="https://github.com/yardstick17"
           aria-label="Follow @yardstick17 on GitHub">Follow @yardstick17</a>
    </span>


</aside>

<!-- Content -->
<article>
    <section id="content">
        <!-- Google Tag Manager (noscript) -->
        <noscript>
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WWHG9QW"
                    height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
        <article>

            <h2 class="post_title post_detail" style="color: #1a1a1a"><a href="https://yardstick17.github.io/image-aesthetic-assessment.html"
                                                                         rel="bookmark"
                                                                         title="Permalink to Image Aesthetic Assessment">Image Aesthetic Assessment</a>
            </h2>

                <img alt="Image Aesthetic Assessment" src="./../images/image_aesthetics_code.jpg" width=100%" style="max-width:1363px">
            <br>
            <div class="entry-content blog-post">
                <p><strong><em>"Beauty is really in the eye of the beholder"</em></strong></p>
<p>Image aesthetics assessment is an attempt to define the <strong>beauty</strong> of an Image.
While everyone has different tastes, there are universally accepted norms when it comes to beauty – things which everyone pretty much agrees are beautiful, like sunsets or sunrises over the mountains or the ocean.</p>
<p>Some of the visual feature that come handy are </p>
<ul>
<li>edge distributions, </li>
<li>color histogram, </li>
<li>Some photographic rules like rue of thirds also determines the beauty of an image.</li>
</ul>
<p>Defining image quality with visual features like other manually curated features are limited in the scope.</p>
<p>The two photographer's story.</p>
<table>
<thead>
<tr>
<th>Great Shot!!</th>
<th>So what?</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="Beautiful Image" src="./../images/resize_thumb_ambiance_amazing_1024.jpg"></td>
<td><img alt="low quality Image" src="./../images/resize_thumb_ambiance_bad_1024.jpg"></td>
</tr>
</tbody>
</table>
<p>The Image is of same place taken with different lightening, angle, adjusted contrast. And it is obvious that image on the left has better aesthetic attire.</p>
<p><strong>Significance of Image Aesthetics</strong></p>
<p>For a platform especially that serves media content, one of the crucial aspect is to show high quality content. With social sites and the given ‘selfie’ trend, we are generating huge amount of data in the form of either images or videos.
 Having a track on the quality will always be helpful.</p>
<table>
<thead>
<tr>
<th>Curated Content</th>
<th>User Generated Content</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="Curated Content" src="./../images/resize_thumb_Screen_Shot_2017_04_15_at_11_18_25_AM_1024.jpg"></td>
<td><img alt="User Generated Content" src="./../images/resize_thumb_Screen_Shot_2017_04_15_at_11_30_00_AM_1024.jpg"></td>
</tr>
</tbody>
</table>
<h2><strong>Can we model such Human Perception?</strong></h2>
<h2><strong>Deep learning</strong></h2>
<p>The topic needs no introduction. It’s a revolution especially in the image classification domain since the last 5 years. With “Alexnet” winning the Image-Net competition, improving error rate with a huge margin acted as spark in the field. Since then, CNN has many state of the arts on its name.</p>
<p><strong>Network architecture of Alexnet.</strong> </p>
<p><img alt="Alexnet architecture" src="./../images/thumb_CNN_image_1024.jpg"></p>
<p>The first layer is input, where input in fed to the network. We can see there pooling operations, convolution operations finally followed by a fully connected layer 
and final softmax layer so that we get values as the probability for each class we label.</p>
<h2><strong>Fixed size input constraint</strong></h2>
<table>
<thead>
<tr>
<th>Input Layer</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="Input Layer" src="./../images/thumb_input_CNN_image_1024.jpg"></td>
<td>Input image <strong>re-sized to 224 * 224</strong> irrespective of original image shape.</td>
</tr>
</tbody>
</table>
<p>We always resize the input feature vector. If the image is larger, image is cropped 
or pad image if image dimensions are smaller, to get a fixed size input to fed the network</p>
<table>
<thead>
<tr>
<th>The Mountains</th>
<th>Qutub Minar</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="Mountains" src="./../images/iceland-blue-lagoon-and-snow-mountains-landscape-header.jpg"></td>
<td><img alt="Qutub Minar" src="./../images/qutub-minar-minaret.jpg"></td>
</tr>
</tbody>
</table>
<p>The above two images are <strong>beautiful in their original aspect ratio.</strong> 
What happens if we re-size the image to a fixed size of 224 * 224? 
Certainly the image will <strong>loose all it’s original aesthetic value!</strong> 
From Landscape to Squared size. All damage is done. The original image composition is lost when image is re-sized.</p>
<h2><strong>Demystifying the Network Architecture</strong></h2>
<p><img alt="Network Architecture" src="./../images/thumb_CNN_image_1024.jpg"></p>
<p>Let’s unveil the hidden layers! So, we can see that after the input , there are few layers of <strong>Operations</strong>. 
The operations are either <strong>Max-pooling</strong> or convolving with a filter i.e. <strong>Convolution</strong>.
So why fixed size of input is required at all then?<br>
It’s because of the <strong>Fully Connected Layer</strong> just before the outputs. 
Fully Connected Layers are in the network for non-linear combination of feature extracted before in convolution network.</p>
<p>Let's understand bit by bit.</p>
<h2><strong>Max Pooling</strong></h2>
<p>Max pooling are there for <strong>Down-sampling</strong> the feature space while maintain the spatial information
Max Pooling in action</p>
<p><img alt="Max Pooling" src="./../images/cropped_max_pooling.gif"></p>
<h2><strong>Spatial Pyramid Pooling</strong></h2>
<p>In spp, an image is divided into bins. Each bin is pooled in its turn. As the number of bins are fixed, 
we always get the <strong>Fixed Shape Output</strong>.</p>
<p>Spp operation in action</p>
<p><img alt="Spatial Pyramid Pooling" src="./../images/sppp_2_cropped.gif"></p>
<p><img alt="Spatial Pyramid Pooling" src="./../images/bin_4_spp.gif"></p>
<h2><strong>Spp Network Architecture</strong></h2>
<p><img alt="Spp Network Architecture" src="./../images/network.png"></p>
<p>The first network is the traditional CNN , we can see the <strong>Max-pool layer</strong> just before the fully connected layer.
In the second architecture, the last max pooling layer is <strong>replaced by a Spp layer</strong>. 
With the <strong>Fixed Bin size (1,2,4)</strong> we make sure that the fully connected layer gets the fixed shape input.</p>
<p><img alt="Spp Network Architecture" src="./../images/687474703a2f2f692e696d6775722e636f6d2f5351574a566f442e706e67.png"></p>
<h2><strong>Training the Spp-Net</strong></h2>
<p>Training the Spp-Net on <strong>live-dataset</strong>, very small dataset, about 1K images total, model achieved the accuracy of 75% on training data, 83% on the test data.</p>
<table>
<thead>
<tr>
<th>Accuracy</th>
<th>Training Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="Spp-Net Accuracy" src="./../images/training_accuracy.png"></td>
<td><img alt="Spp-Net Training Loss" src="./../images/training_loss.png"></td>
</tr>
</tbody>
</table>
<h2><strong>Takeaways</strong></h2>
<p><strong>With Spp in Network</strong>  </p>
<ul>
<li>Model learns the scale invariant feature like SIFT(traditional image processing algorithm).</li>
<li>One of the challenge in text classification with Deep learning is the fixed size feature vector representation of sentence.</li>
</ul>
<h2><strong>Interesting Results</strong></h2>
<p>After training model, I experimented for few results. These are the most interesting and promising results I found.</p>
<table>
<thead>
<tr>
<th>Blurred Cropped Image</th>
<th>Complete Image</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="Blurred Image" src="./../images/low_quality_blurred_image.jpg"></td>
<td><img alt="Complete Image" src="./../images/high_quality_blurred_image.jpg"></td>
</tr>
</tbody>
</table>
<p>I recently came across this <a href="https://philliphaumesserphotography.com">Photographer</a> experience from being a amateur to professional.<br>
He proved what difference a change in perspective can make. So, I decided to make my trained model judge for his efficacy.</p>
<table>
<thead>
<tr>
<th>Amateur Click? Yes, it is.</th>
<th>Pro Click? I am already amazed.</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="Beautiful Image" src="../images/amateur_photographer.png"></td>
<td><img alt="low quality Image" src="../images/professionl_photographer.png"></td>
</tr>
</tbody>
</table>
<p>The aesthetic trained model has passed him with flying colors in Photographic skills. Well done Phillip Haumesser.</p>
<h2><strong>References</strong></h2>
<ul>
<li><a href="https://arxiv.org/abs/1406.4729">Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a></li>
<li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, ImageNet Classification with Deep Convolutional Neural Networks 2012</a></li>
<li><a href="https://ieeexplore.ieee.org/document/7780429/">Long Mai, Hailin Jin, Feing Liu, Composition-Preserving Deep Photo Aesthetics Assessment</a></li>
</ul>
<p>With that I would like to wrap up. Any Questions ?</p>
            </div>

            <div class="post_list">
                <div class="entry-social">
                        <span>
                        <a class="github-button" href="https://github.com/yardstick17/ConnectingDots"
                           aria-label="View Code on GitHub"> View on Github
                        </a>
                        </span>

                    <span>
                    <a class="twitter-share-button"
                       href="https://twitter.com/share"
                       data-text="Image Aesthetic Assessment"
                       data-url="https://yardstick17.github.io/image-aesthetic-assessment.html"
                       data-hashtags="[<Tag 'image quality prediction'>, <Tag 'spatial pyramid pooling'>, <Tag 'spp-net'>, <Tag 'deep learning'>]"
                       data-via="imYardstick17"
                    >
                        Tweet
                    </a>
                    </span>
                    <span>
                        <a class="github-button" href="https://github.com/yardstick17"
                           aria-label="Follow @yardstick17 on GitHub">Follow
                        @yardstick17</a>
                    </span>
                </div>

                <span>By </span>
                <a href="https://yardstick17.github.io/author/amit-kushwaha.html">@Amit Kushwaha</a>
                <span> in </span>
                <span class="post_category"><a href="https://yardstick17.github.io/category/deep-learning.html" rel="bookmark"
                                               title="Permalink to Deep Learning">[ Deep Learning ]</a></span>
                <span class="post_date">Sat 01 April 2017</span>
                <div><span>Tags : </span>
                            <span><a href="https://yardstick17.github.io/tag/image-quality-prediction.html">#image quality prediction, </a></span>
                            <span><a href="https://yardstick17.github.io/tag/spatial-pyramid-pooling.html">#spatial pyramid pooling, </a></span>
                            <span><a href="https://yardstick17.github.io/tag/spp-net.html">#spp-net, </a></span>
                            <span><a href="https://yardstick17.github.io/tag/deep-learning.html">#deep learning, </a></span>
                </div>


            </div>

                <div class="comments">
                    <h2>Comments !</h2>
                    <div id="disqus_thread"></div>
                    <script type="text/javascript">
                        var disqus_identifier = "image-aesthetic-assessment.html";
                        (function () {
                            var dsq = document.createElement('script');
                            dsq.type = 'text/javascript';
                            dsq.async = true;
                            dsq.src = 'https://amitkushwaha.disqus.com/embed.js';
                            (document.getElementsByTagName('head')[0] ||
                            document.getElementsByTagName('body')[0]).appendChild(dsq);
                        })();
                    </script>
                </div>
        </article>
    </section>
</article>

<!-- Footer -->
    <footer>
        <p>He was a fool who didn't know it was impossible. So he did it.</p>
    </footer>

    <!-- Analytics -->
    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-98482392-1']);
        _gaq.push(['_trackPageview']);
        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>